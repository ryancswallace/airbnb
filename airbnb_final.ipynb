{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Pricing Prediction: Final\n",
    "**James Gearheart**<br>\n",
    "**Danny Zhuang**<br>\n",
    "**Bob Saludo**<br>\n",
    "**Ryan Wallace**<br><br>\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**TF: Christine Hwang**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "encoding of categoricals\n",
    "\n",
    "transformations of cts features\n",
    "\n",
    "selection of features\n",
    "\n",
    "fix or justify biasing of model/violation of independence of observations (hierarchical model?)\n",
    "\n",
    "ridge regression and tuning\n",
    "\n",
    "lasso regression and tuning\n",
    "\n",
    "random forest regression and tuning\n",
    "\n",
    "prediction intervals around predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import csv\n",
    "import datetime\n",
    "import operator\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RyanWallace/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (0,2,6,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read the three cleaned datasets\n",
    "listings_df = pd.read_csv('datasets/listings_final.csv', delimiter=',', index_col=0)\n",
    "reviews_df = pd.read_csv('datasets/reviews_final.csv', delimiter=',', index_col=0)\n",
    "calendar_df = pd.read_csv('datasets/calendar_final.csv', index_col=0)\n",
    "\n",
    "# log transform prices in calendar\n",
    "calendar_df['price_log'] = np.log(calendar_df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listing_id' 'date' 'price' 'diff_mean' 'price_log']\n",
      "['listing_id' 'neighbourhood' 'neighbourhood_cleansed' 'city' 'zipcode'\n",
      " 'market' 'latitude' 'longitude' 'is_location_exact' 'property_type'\n",
      " 'room_type' 'accommodates' 'bathrooms' 'bedrooms' 'beds' 'bed_type'\n",
      " 'price' 'guests_included' 'extra_people' 'minimum_nights' 'maximum_nights'\n",
      " 'availability_30' 'availability_60' 'availability_90' 'availability_365'\n",
      " 'number_of_reviews' 'review_scores_rating' 'review_scores_accuracy'\n",
      " 'review_scores_cleanliness' 'review_scores_checkin'\n",
      " 'review_scores_communication' 'review_scores_location'\n",
      " 'review_scores_value' 'host_listing_count' 'price_log']\n"
     ]
    }
   ],
   "source": [
    "calendar_df.drop(['available'], axis=1, inplace=True, errors='ignore')\n",
    "listings_df.drop(['scrape_id', 'last_scraped', 'name', 'picture_url', 'host_id', 'host_name', 'host_since',\n",
    "                  'host_picture_url', 'weekly_price', 'monthly_price', 'calendar_last_scraped', 'calendar_updated',\n",
    "                  'street', 'market', 'extra_people'], axis=1, inplace=True, errors='ignore')\n",
    "print calendar_df.columns.values\n",
    "print listings_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create calendar with listings data added\n",
    "calendar_expanded_df = calendar_df.merge(listings_df, on='listing_id', how='left', suffixes=['_calendar', '_listings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar entries before stripping: (7201883, 39)\n",
      "calendar entries after stripping: (7201153, 39)\n"
     ]
    }
   ],
   "source": [
    "# strip errant NaN's and infinites from data import errors and log transformation\n",
    "print 'calendar entries before stripping:', calendar_expanded_df.shape\n",
    "calendar_expanded_df = calendar_expanded_df.replace([np.inf, -np.inf], np.nan)\n",
    "calendar_expanded_df = calendar_expanded_df.dropna()\n",
    "print 'calendar entries after stripping:', calendar_expanded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to convert date to day of week\n",
    "def get_day(date):\n",
    "    return datetime.datetime.strptime(date, '%Y-%m-%d').strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create indicators for time variables\n",
    "# weekend\n",
    "dates = np.array(calendar_expanded_df['date'])\n",
    "days = [get_day(date) for date in dates]\n",
    "weekend = [1 if day == 'Friday' or day == 'Saturday' else 0 for day in days]\n",
    "calendar_expanded_df['weekend'] = pd.Series(np.array(weekend), index=calendar_expanded_df.index)\n",
    "\n",
    "# major holidys (around New Years)\n",
    "holiday_dates = ['2015-01-01', '2015-01-02', '2015-01-03']\n",
    "holiday = [1 if date in holiday_dates else 0 for date in dates]\n",
    "calendar_expanded_df['holiday'] = pd.Series(np.array(holiday), index=calendar_expanded_df.index)\n",
    "\n",
    "# not January (excluding Holidays) or February\n",
    "slump_dates = []\n",
    "for d in range(4, 10):\n",
    "    slump_dates.append('2015-01-0' + str(d))\n",
    "for d in range(10, 32):\n",
    "    slump_dates.append('2015-01-' + str(d))\n",
    "for d in range(1, 10):\n",
    "    slump_dates.append('2015-02-0' + str(d))\n",
    "for d in range(10, 29):\n",
    "    slump_dates.append('2015-01-' + str(d))\n",
    "slump = [1 if date in slump_dates else 0 for date in dates]\n",
    "calendar_expanded_df['slump'] = pd.Series(np.array(slump), index=calendar_expanded_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find means by zipcode and group into zipcodes\n",
    "neighborhoods = calendar_expanded_df['neighbourhood'].unique()\n",
    "zipcodes = calendar_expanded_df['zipcode'].unique()\n",
    "\n",
    "neighborhood_prices = []\n",
    "for neighborhood in neighborhoods:\n",
    "    neighborhood_prices.append((neighborhood, np.mean(np.array(listings_df[listings_df['neighbourhood'] == neighborhood]['price']))))\n",
    "\n",
    "zipcode_prices = []\n",
    "for zipcode in zipcodes:\n",
    "    zipcode_prices.append((zipcode, np.mean(np.array(listings_df[listings_df['zipcode'] == zipcode]['price']))))\n",
    "    \n",
    "# group zipcodes and neighborhoods into quartiles by average\n",
    "neighborhood_prices.sort(key=operator.itemgetter(1), reverse=True)\n",
    "zipcode_prices.sort(key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find size of quartiles\n",
    "neighborhood_quartile_size = int(np.round(len(neighborhood_prices)*0.25))\n",
    "zipcode_quartile_size = int(np.round(len(zipcode_prices)*0.25))\n",
    "\n",
    "# break up neighboorhood and zipcodes by quartile\n",
    "neighborhood_1 = neighborhood_prices[:neighborhood_quartile_size]\n",
    "neighborhood_2 = neighborhood_prices[neighborhood_quartile_size:2*neighborhood_quartile_size]\n",
    "neighborhood_3 = neighborhood_prices[2*neighborhood_quartile_size:3*neighborhood_quartile_size]\n",
    "neighborhood_4 = neighborhood_prices[3*neighborhood_quartile_size:]\n",
    "\n",
    "zipcode_1 = zipcode_prices[:zipcode_quartile_size]\n",
    "zipcode_2 = zipcode_prices[zipcode_quartile_size:2*zipcode_quartile_size]\n",
    "zipcode_3 = zipcode_prices[2*zipcode_quartile_size:3*zipcode_quartile_size]\n",
    "zipcode_4 = zipcode_prices[3*zipcode_quartile_size:]\n",
    "\n",
    "# create new indicators for each quartile\n",
    "neighborhoods = np.array(calendar_expanded_df['neighbourhood'])\n",
    "zipcodes = np.array(calendar_expanded_df['zipcode'])\n",
    "\n",
    "neighborhood_q1 = []\n",
    "neighborhood_q2 = []\n",
    "neighborhood_q3 = []\n",
    "neighborhood_q4 = []\n",
    "\n",
    "zipcode_q1 = []\n",
    "zipcode_q2 = []\n",
    "zipcode_q3 = []\n",
    "zipcode_q4 = []\n",
    "\n",
    "for neighborhood in neighborhoods:\n",
    "    if neighborhood in neighborhood_1:\n",
    "        neighborhood_q1.append(1)\n",
    "    else:\n",
    "        neighborhood_q1.append(0)\n",
    "    \n",
    "    if neighborhood in neighborhood_2:\n",
    "        neighborhood_q2.append(1)\n",
    "    else:\n",
    "        neighborhood_q2.append(0)\n",
    "    \n",
    "    if neighborhood in neighborhood_3:\n",
    "        neighborhood_q3.append(1)\n",
    "    else:\n",
    "        neighborhood_q3.append(0)\n",
    "        \n",
    "    if neighborhood in neighborhood_4:\n",
    "        neighborhood_q4.append(1)\n",
    "    else:\n",
    "        neighborhood_q4.append(0)\n",
    "        \n",
    "for zipcode in zipcodes:\n",
    "    if zipcode in zipcode_1:\n",
    "        zipcode_q1.append(1)\n",
    "    else:\n",
    "        zipcode_q1.append(0)\n",
    "    \n",
    "    if zipcode in zipcode_2:\n",
    "        zipcode_q2.append(1)\n",
    "    else:\n",
    "        zipcode_q2.append(0)\n",
    "    \n",
    "    if zipcode in zipcode_3:\n",
    "        zipcode_q3.append(1)\n",
    "    else:\n",
    "        zipcode_q3.append(0)\n",
    "        \n",
    "    if zipcode in zipcode_4:\n",
    "        zipcode_q4.append(1)\n",
    "    else:\n",
    "        zipcode_q4.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# binarize categorical variables\n",
    "property_type_array = np.array(calendar_expanded_df['property_type'])\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "property_types_binarized = lb.fit_transform(property_type_array)\n",
    "\n",
    "is_location_exact_array = np.array(calendar_expanded_df['is_location_exact'])\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "is_location_exact_binarized = lb.fit_transform(is_location_exact_array)\n",
    "\n",
    "room_type_array = np.array(calendar_expanded_df['room_type'])\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "room_type_binarized = lb.fit_transform(room_type_array)\n",
    "\n",
    "bed_type_array = np.array(calendar_expanded_df['bed_type'])\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "bed_type_binarized = lb.fit_transform(bed_type_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201153, 18)\n"
     ]
    }
   ],
   "source": [
    "print property_types_binarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract relevant feature listing\n",
    "relevant_vars1 = ['bathrooms', 'bedrooms', 'beds', 'accommodates', 'longitude', \n",
    "                  'weekend', 'holiday', 'slump']\n",
    "relevant_vars2 = ['latitude' 'longitude' \n",
    "  'accommodates' 'bathrooms' 'bedrooms' 'beds' \n",
    " 'guests_included' 'minimum_nights' 'maximum_nights'\n",
    " 'availability_30' 'availability_60' 'availability_90' 'availability_365'\n",
    " 'number_of_reviews' 'review_scores_rating' 'review_scores_accuracy'\n",
    " 'review_scores_cleanliness' 'review_scores_checkin'\n",
    " 'review_scores_communication' 'review_scores_location'\n",
    " 'review_scores_value' 'host_listing_count']\n",
    "\n",
    "X_df = calendar_expanded_df[relevant_vars].copy()\n",
    "y_df = calendar_expanded_df[['price_log_calendar']].copy()\n",
    "\n",
    "# numpy for sklearn\n",
    "X = X_df.as_matrix()\n",
    "y = y_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert zipcode, neighborhood lists to np arrays\n",
    "zipcode_q1 = np.resize(np.array(zipcode_q1), (len(zipcode_q1), 1))\n",
    "zipcode_q2 = np.resize(np.array(zipcode_q2), (len(zipcode_q2), 1))\n",
    "zipcode_q3 = np.resize(np.array(zipcode_q3), (len(zipcode_q3), 1))\n",
    "zipcode_q4 = np.resize(np.array(zipcode_q4), (len(zipcode_q4), 1))\n",
    "\n",
    "neighborhood_q1 = np.resize(np.array(neighborhood_q1), (len(neighborhood_q1), 1))\n",
    "neighborhood_q2 = np.resize(np.array(neighborhood_q2), (len(neighborhood_q2), 1))\n",
    "neighborhood_q3 = np.resize(np.array(neighborhood_q3), (len(neighborhood_q3), 1))\n",
    "neighborhood_q4 = np.resize(np.array(neighborhood_q4), (len(neighborhood_q4), 1))\n",
    "\n",
    "# add categorical vars to X\n",
    "Xy = np.concatenate((X, zipcode_q1, zipcode_q2, zipcode_q3, zipcode_q4, \n",
    "                neighborhood_q1, neighborhood_q2, neighborhood_q3, \n",
    "                neighborhood_q4, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "# use 75% for training, the rest for testing\n",
    "num_train = int(np.round(Xy.shape[0]*0.75))\n",
    "\n",
    "# shuffle for random selection\n",
    "random.shuffle(Xy)\n",
    "\n",
    "# pull out sets\n",
    "X_train = Xy[:num_train,:(-1)]\n",
    "X_test = Xy[num_train:,:(-1)]\n",
    "y_train = Xy[:num_train, -1]\n",
    "y_test = Xy[num_train:, -1]\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "y_test = np.nan_to_num(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 in test:  0.378520858319\n"
     ]
    }
   ],
   "source": [
    "# fit simple linear regression\n",
    "linear_model = LinReg()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print 'R^2 in test: ', linear_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
