{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Pricing Prediction: Final\n",
    "**James Gearheart**<br>\n",
    "**Danny Zhuang**<br>\n",
    "**Bob Saludo**<br>\n",
    "**Ryan Wallace**<br><br>\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**TF: Christine Hwang**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "encoding of categoricals\n",
    "\n",
    "transformations of cts features\n",
    "\n",
    "duplicate listings so all properties have 365 observations  (I realized doing this will remove the bias towards dates that appear more frequently, but replace it with bias towards houses that are offered less. I can't see any way around this)\n",
    "\n",
    "ridge regression and tuning\n",
    "\n",
    "lasso regression and tuning\n",
    "\n",
    "random forest regression and tuning\n",
    "\n",
    "prediction intervals around predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import csv\n",
    "import datetime\n",
    "import operator\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RyanWallace/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (0,2,6,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read the three cleaned datasets\n",
    "listings_df = pd.read_csv('datasets/listings_final.csv', delimiter=',', index_col=0)\n",
    "reviews_df = pd.read_csv('datasets/reviews_final.csv', delimiter=',', index_col=0)\n",
    "calendar_df = pd.read_csv('datasets/calendar_final.csv', index_col=0)\n",
    "\n",
    "# log transform prices in calendar\n",
    "calendar_df['price_log'] = np.log(calendar_df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listing_id' 'date' 'price' 'diff_mean' 'price_log']\n",
      "['listing_id' 'neighbourhood' 'neighbourhood_cleansed' 'city' 'zipcode'\n",
      " 'market' 'latitude' 'longitude' 'is_location_exact' 'property_type'\n",
      " 'room_type' 'accommodates' 'bathrooms' 'bedrooms' 'beds' 'bed_type'\n",
      " 'price' 'guests_included' 'extra_people' 'minimum_nights' 'maximum_nights'\n",
      " 'availability_30' 'availability_60' 'availability_90' 'availability_365'\n",
      " 'number_of_reviews' 'review_scores_rating' 'review_scores_accuracy'\n",
      " 'review_scores_cleanliness' 'review_scores_checkin'\n",
      " 'review_scores_communication' 'review_scores_location'\n",
      " 'review_scores_value' 'host_listing_count' 'price_log']\n"
     ]
    }
   ],
   "source": [
    "calendar_df.drop(['available'], axis=1, inplace=True, errors='ignore')\n",
    "listings_df.drop(['scrape_id', 'last_scraped', 'name', 'picture_url', 'host_id', 'host_name', 'host_since',\n",
    "                  'host_picture_url', 'weekly_price', 'monthly_price', 'calendar_last_scraped', 'calendar_updated',\n",
    "                  'street', 'market', 'extra_people'], axis=1, inplace=True, errors='ignore')\n",
    "print calendar_df.columns.values\n",
    "print listings_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create calendar with listings data added\n",
    "calendar_expanded_df = calendar_df.merge(listings_df, on='listing_id', how='left', suffixes=['_calendar', '_listings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar entries before stripping: (7201883, 39)\n",
      "calendar entries after stripping: (7201153, 39)\n"
     ]
    }
   ],
   "source": [
    "# strip errant NaN's and infinites from data import errors and log transformation\n",
    "print 'calendar entries before stripping:', calendar_expanded_df.shape\n",
    "calendar_expanded_df = calendar_expanded_df.replace([np.inf, -np.inf], np.nan)\n",
    "calendar_expanded_df = calendar_expanded_df.dropna()\n",
    "print 'calendar entries after stripping:', calendar_expanded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to convert date to day of week\n",
    "def get_day(date):\n",
    "    return datetime.datetime.strptime(date, '%Y-%m-%d').strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create indicators for time variables\n",
    "# weekend\n",
    "dates = np.array(calendar_expanded_df['date'])\n",
    "days = [get_day(date) for date in dates]\n",
    "weekend = [1 if day == 'Friday' or day == 'Saturday' else 0 for day in days]\n",
    "calendar_expanded_df['weekend'] = pd.Series(np.array(weekend), index=calendar_expanded_df.index)\n",
    "\n",
    "# major holidys (around New Years)\n",
    "holiday_dates = ['2015-01-01', '2015-01-02', '2015-01-03']\n",
    "holiday = [1 if date in holiday_dates else 0 for date in dates]\n",
    "calendar_expanded_df['holiday'] = pd.Series(np.array(holiday), index=calendar_expanded_df.index)\n",
    "\n",
    "# not January (excluding Holidays) or February\n",
    "slump_dates = []\n",
    "for d in range(4, 10):\n",
    "    slump_dates.append('2015-01-0' + str(d))\n",
    "for d in range(10, 32):\n",
    "    slump_dates.append('2015-01-' + str(d))\n",
    "for d in range(1, 10):\n",
    "    slump_dates.append('2015-02-0' + str(d))\n",
    "for d in range(10, 29):\n",
    "    slump_dates.append('2015-01-' + str(d))\n",
    "slump = [1 if date in slump_dates else 0 for date in dates]\n",
    "calendar_expanded_df['slump'] = pd.Series(np.array(slump), index=calendar_expanded_df.index)\n",
    "\n",
    "# Jan (after Jan 3), Feb, and March each appear to have different values\n",
    "jan_dates = []\n",
    "feb_dates = []\n",
    "march_dates = []\n",
    "for d in range(4, 10):\n",
    "    jan_dates.append('2015-01-0' + str(d))\n",
    "for d in range(10, 32):\n",
    "    jan_dates.append('2015-01-' + str(d))\n",
    "for d in range(1, 10):\n",
    "    feb_dates.append('2015-02-0' + str(d))\n",
    "for d in range(10, 29):\n",
    "    feb_dates.append('2015-01-' + str(d))\n",
    "for d in range(1, 10):\n",
    "    march_dates.append('2015-01-0' + str(d))\n",
    "for d in range(10, 32):\n",
    "    march_dates.append('2015-01-' + str(d))\n",
    "jan = [1 if date in jan_dates else 0 for date in dates]\n",
    "feb = [1 if date in feb_dates else 0 for date in dates]\n",
    "march = [1 if date in march_dates else 0 for date in dates]\n",
    "\n",
    "calendar_expanded_df['jan'] = pd.Series(np.array(jan), index=calendar_expanded_df.index)\n",
    "calendar_expanded_df['feb'] = pd.Series(np.array(feb), index=calendar_expanded_df.index)\n",
    "calendar_expanded_df['march'] = pd.Series(np.array(march), index=calendar_expanded_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find means by zipcode and group into zipcodes\n",
    "neighborhoods = calendar_expanded_df['neighbourhood'].unique()\n",
    "zipcodes = calendar_expanded_df['zipcode'].unique()\n",
    "\n",
    "neighborhood_prices = []\n",
    "for neighborhood in neighborhoods:\n",
    "    neighborhood_prices.append((neighborhood, np.mean(np.array(listings_df[listings_df['neighbourhood'] == neighborhood]['price']))))\n",
    "\n",
    "zipcode_prices = []\n",
    "for zipcode in zipcodes:\n",
    "    zipcode_prices.append((zipcode, np.mean(np.array(listings_df[listings_df['zipcode'] == zipcode]['price']))))\n",
    "    \n",
    "# group zipcodes and neighborhoods into quartiles by average\n",
    "neighborhood_prices.sort(key=operator.itemgetter(1), reverse=True)\n",
    "zipcode_prices.sort(key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find size of quartiles\n",
    "neighborhood_quartile_size = int(np.round(len(neighborhood_prices)*0.25))\n",
    "zipcode_quartile_size = int(np.round(len(zipcode_prices)*0.25))\n",
    "\n",
    "# break up neighboorhood and zipcodes by quartile\n",
    "neighborhood_1 = neighborhood_prices[:neighborhood_quartile_size]\n",
    "neighborhood_2 = neighborhood_prices[neighborhood_quartile_size:2*neighborhood_quartile_size]\n",
    "neighborhood_3 = neighborhood_prices[2*neighborhood_quartile_size:3*neighborhood_quartile_size]\n",
    "neighborhood_4 = neighborhood_prices[3*neighborhood_quartile_size:]\n",
    "\n",
    "zipcode_1 = zipcode_prices[:zipcode_quartile_size]\n",
    "zipcode_2 = zipcode_prices[zipcode_quartile_size:2*zipcode_quartile_size]\n",
    "zipcode_3 = zipcode_prices[2*zipcode_quartile_size:3*zipcode_quartile_size]\n",
    "zipcode_4 = zipcode_prices[3*zipcode_quartile_size:]\n",
    "\n",
    "# create new indicators for each quartile\n",
    "neighborhoods = np.array(calendar_expanded_df['neighbourhood'])\n",
    "zipcodes = np.array(calendar_expanded_df['zipcode'])\n",
    "\n",
    "neighborhood_q1 = []\n",
    "neighborhood_q2 = []\n",
    "neighborhood_q3 = []\n",
    "neighborhood_q4 = []\n",
    "\n",
    "zipcode_q1 = []\n",
    "zipcode_q2 = []\n",
    "zipcode_q3 = []\n",
    "zipcode_q4 = []\n",
    "\n",
    "for neighborhood in neighborhoods:\n",
    "    if neighborhood in neighborhood_1:\n",
    "        neighborhood_q1.append(1)\n",
    "    else:\n",
    "        neighborhood_q1.append(0)\n",
    "    \n",
    "    if neighborhood in neighborhood_2:\n",
    "        neighborhood_q2.append(1)\n",
    "    else:\n",
    "        neighborhood_q2.append(0)\n",
    "    \n",
    "    if neighborhood in neighborhood_3:\n",
    "        neighborhood_q3.append(1)\n",
    "    else:\n",
    "        neighborhood_q3.append(0)\n",
    "        \n",
    "    if neighborhood in neighborhood_4:\n",
    "        neighborhood_q4.append(1)\n",
    "    else:\n",
    "        neighborhood_q4.append(0)\n",
    "        \n",
    "for zipcode in zipcodes:\n",
    "    if zipcode in zipcode_1:\n",
    "        zipcode_q1.append(1)\n",
    "    else:\n",
    "        zipcode_q1.append(0)\n",
    "    \n",
    "    if zipcode in zipcode_2:\n",
    "        zipcode_q2.append(1)\n",
    "    else:\n",
    "        zipcode_q2.append(0)\n",
    "    \n",
    "    if zipcode in zipcode_3:\n",
    "        zipcode_q3.append(1)\n",
    "    else:\n",
    "        zipcode_q3.append(0)\n",
    "        \n",
    "    if zipcode in zipcode_4:\n",
    "        zipcode_q4.append(1)\n",
    "    else:\n",
    "        zipcode_q4.append(0)\n",
    "\n",
    "# convert zipcode, neighborhood lists to np arrays\n",
    "calendar_expanded_df['zipcode_q1'] = pd.Series(np.resize(np.array(zipcode_q1), (len(zipcode_q1), 1)))\n",
    "calendar_expanded_df['zipcode_q2'] = pd.Series(np.resize(np.array(zipcode_q2), (len(zipcode_q2), 1)))\n",
    "calendar_expanded_df['zipcode_q3'] = pd.Series(np.resize(np.array(zipcode_q3), (len(zipcode_q3), 1)))\n",
    "calendar_expanded_df['zipcode_q4'] = pd.Series(np.resize(np.array(zipcode_q4), (len(zipcode_q4), 1)))\n",
    "\n",
    "calendar_expanded_df['neighborhood_q1'] = pd.Series(np.resize(np.array(neighborhood_q1), (len(neighborhood_q1), 1)))\n",
    "calendar_expanded_df['neighborhood_q2'] = pd.Series(np.resize(np.array(neighborhood_q2), (len(neighborhood_q2), 1)))\n",
    "calendar_expanded_df['neighborhood_q3'] = pd.Series(np.resize(np.array(neighborhood_q3), (len(neighborhood_q3), 1)))\n",
    "calendar_expanded_df['neighborhood_q4'] = pd.Series(np.resize(np.array(neighborhood_q4), (len(neighborhood_q4), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binarize categorical variables\n",
    "property_type_dummies = pd.get_dummies(calendar_expanded_df['property_type'])\n",
    "property_type_cols = list(property_type_dummies.columns.values)\n",
    "\n",
    "is_location_exact_dummies = pd.get_dummies(calendar_expanded_df['is_location_exact'])\n",
    "is_location_exact_cols = list(is_location_exact_dummies.columns.values)\n",
    "\n",
    "room_type_dummies = pd.get_dummies(calendar_expanded_df['room_type'])\n",
    "room_type_cols = list(room_type_dummies.columns.values)\n",
    "\n",
    "bed_type_dummies = pd.get_dummies(calendar_expanded_df['bed_type'])\n",
    "bed_type_cols = list(bed_type_dummies.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property_type_cols:  ['Apartment', 'Bed & Breakfast', 'Boat', 'Cabin', 'Camper/RV', 'Castle', 'Cave', 'Chalet', 'Dorm', 'Earth House', 'House', 'Hut', 'Lighthouse', 'Loft', 'Other', 'Tent', 'Treehouse', 'Villa']\n",
      "is_location_exact_cols:  ['f', 't']\n",
      "room_type_cols:  ['Entire home/apt', 'Private room', 'Shared room']\n",
      "bed_type_cols:  ['Airbed', 'Couch', 'Futon', 'Pull-out Sofa', 'Real Bed']\n"
     ]
    }
   ],
   "source": [
    "print 'property_type_cols: ', property_type_cols\n",
    "print 'is_location_exact_cols: ', is_location_exact_cols\n",
    "print 'room_type_cols: ', room_type_cols\n",
    "print 'bed_type_cols: ', bed_type_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize continusous random variables against response variable\n",
    "# to determine if any transformations of the predictors would be helpful\n",
    "cts_vars_to_plot = ['latitude', 'longitude',\n",
    "                    'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "                    'guests_included', 'minimum_nights', 'maximum_nights',\n",
    "                    'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                    'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy',\n",
    "                    'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                    'review_scores_communication', 'review_scores_location',\n",
    "                    'review_scores_value', 'host_listing_count']\n",
    "\n",
    "fig, ax = plt.subplots(1, len(cts_vars_to_plot), figsize=(20, 5*len(cts_vars_to_plot)))\n",
    "for i, var in enumerate(cts_vars_to_plot):\n",
    "    ax[i].scatter(calendar_expanded_df[var], calendar_expanded_df['price_log_calendar'])\n",
    "    ax[i].set_title('Log Price against ' + var)\n",
    "    ax[i].set_xlabel(var)\n",
    "    ax[i].set_ylabel('Log Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zipcode_q1', 'zipcode_q2', 'zipcode_q3', 'zipcode_q4', 'neighborhood_q1', 'neighborhood_q2', 'neighborhood_q3', 'neighborhood_q4', 'Apartment', 'Bed & Breakfast', 'Boat', 'Cabin', 'Camper/RV', 'Castle', 'Cave', 'Chalet', 'Dorm', 'Earth House', 'House', 'Hut', 'Lighthouse', 'Loft', 'Other', 'Tent', 'Treehouse', 'Villa', 'f', 't', 'Entire home/apt', 'Private room', 'Shared room', 'Airbed', 'Couch', 'Futon', 'Pull-out Sofa', 'Real Bed']\n"
     ]
    }
   ],
   "source": [
    "# extract relevant feature listing\n",
    "relevant_vars1 = ['bathrooms', 'bedrooms', 'beds', 'accommodates', 'longitude', \n",
    "                  'weekend', 'holiday', 'slump']\n",
    "\n",
    "cts_vars = ['latitude', 'longitude', \n",
    "            'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "            'guests_included', 'minimum_nights', 'maximum_nights',\n",
    "            'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "            'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy',\n",
    "            'review_scores_cleanliness', 'review_scores_checkin',\n",
    "            'review_scores_communication', 'review_scores_location',\n",
    "            'review_scores_value', 'host_listing_count']\n",
    "\n",
    "categorical_vars = ['zipcode_q1', 'zipcode_q2', 'zipcode_q3', 'zipcode_q4',\n",
    "                   'neighborhood_q1', 'neighborhood_q2', 'neighborhood_q3', 'neighborhood_q4',\n",
    "                   'weekend', 'holiday', 'slump', 'jan', 'feb', 'march'] + \\\n",
    "                    property_type_cols + is_location_exact_cols + room_type_cols + bed_type_cols\n",
    "\n",
    "X_df = calendar_expanded_df[cts_vars, categorical_vars].copy()\n",
    "y_df = calendar_expanded_df[['price_log_calendar']].copy()\n",
    "\n",
    "# numpy for sklearn\n",
    "X = X_df.as_matrix()\n",
    "y = y_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "Xy = np.concatenate((X, y), axis=1)\n",
    "\n",
    "# use 75% for training, the rest for testing\n",
    "num_train = int(np.round(Xy.shape[0]*0.75))\n",
    "\n",
    "# shuffle for random selection\n",
    "random.shuffle(Xy)\n",
    "\n",
    "# pull out sets\n",
    "X_train = Xy[:num_train,:(-1)]\n",
    "X_test = Xy[num_train:,:(-1)]\n",
    "y_train = Xy[:num_train, -1]\n",
    "y_test = Xy[num_train:, -1]\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "y_test = np.nan_to_num(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 in test:  0.378520858319\n"
     ]
    }
   ],
   "source": [
    "# fit simple linear regression\n",
    "linear_model = LinReg()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print 'R^2 in test: ', linear_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
